{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9272430325061904,
  "eval_steps": 500,
  "global_step": 2200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00421474105684632,
      "grad_norm": 0.7355169653892517,
      "learning_rate": 9.962057335581789e-06,
      "loss": 1.7892,
      "step": 10
    },
    {
      "epoch": 0.00842948211369264,
      "grad_norm": 0.559560239315033,
      "learning_rate": 9.919898819561552e-06,
      "loss": 1.6528,
      "step": 20
    },
    {
      "epoch": 0.01264422317053896,
      "grad_norm": 0.48642784357070923,
      "learning_rate": 9.877740303541317e-06,
      "loss": 1.6026,
      "step": 30
    },
    {
      "epoch": 0.01685896422738528,
      "grad_norm": 0.45048466324806213,
      "learning_rate": 9.83558178752108e-06,
      "loss": 1.5838,
      "step": 40
    },
    {
      "epoch": 0.0210737052842316,
      "grad_norm": 0.4642116129398346,
      "learning_rate": 9.793423271500844e-06,
      "loss": 1.582,
      "step": 50
    },
    {
      "epoch": 0.02528844634107792,
      "grad_norm": 0.43488791584968567,
      "learning_rate": 9.751264755480608e-06,
      "loss": 1.5549,
      "step": 60
    },
    {
      "epoch": 0.02950318739792424,
      "grad_norm": 0.4448527991771698,
      "learning_rate": 9.709106239460371e-06,
      "loss": 1.5508,
      "step": 70
    },
    {
      "epoch": 0.03371792845477056,
      "grad_norm": 0.4592684209346771,
      "learning_rate": 9.666947723440136e-06,
      "loss": 1.545,
      "step": 80
    },
    {
      "epoch": 0.03793266951161688,
      "grad_norm": 0.4484090507030487,
      "learning_rate": 9.6247892074199e-06,
      "loss": 1.549,
      "step": 90
    },
    {
      "epoch": 0.0421474105684632,
      "grad_norm": 0.45611315965652466,
      "learning_rate": 9.582630691399663e-06,
      "loss": 1.5435,
      "step": 100
    },
    {
      "epoch": 0.04636215162530952,
      "grad_norm": 0.42837661504745483,
      "learning_rate": 9.540472175379427e-06,
      "loss": 1.5431,
      "step": 110
    },
    {
      "epoch": 0.05057689268215584,
      "grad_norm": 0.4304472804069519,
      "learning_rate": 9.498313659359192e-06,
      "loss": 1.5281,
      "step": 120
    },
    {
      "epoch": 0.05479163373900216,
      "grad_norm": 0.4470120370388031,
      "learning_rate": 9.456155143338955e-06,
      "loss": 1.5265,
      "step": 130
    },
    {
      "epoch": 0.05900637479584848,
      "grad_norm": 0.44037166237831116,
      "learning_rate": 9.413996627318719e-06,
      "loss": 1.5432,
      "step": 140
    },
    {
      "epoch": 0.0632211158526948,
      "grad_norm": 0.4386763572692871,
      "learning_rate": 9.371838111298484e-06,
      "loss": 1.5339,
      "step": 150
    },
    {
      "epoch": 0.06743585690954113,
      "grad_norm": 0.44748035073280334,
      "learning_rate": 9.329679595278247e-06,
      "loss": 1.5453,
      "step": 160
    },
    {
      "epoch": 0.07165059796638744,
      "grad_norm": 0.4410596191883087,
      "learning_rate": 9.28752107925801e-06,
      "loss": 1.5367,
      "step": 170
    },
    {
      "epoch": 0.07586533902323377,
      "grad_norm": 0.4436720907688141,
      "learning_rate": 9.245362563237776e-06,
      "loss": 1.5304,
      "step": 180
    },
    {
      "epoch": 0.08008008008008008,
      "grad_norm": 0.42842480540275574,
      "learning_rate": 9.20320404721754e-06,
      "loss": 1.5272,
      "step": 190
    },
    {
      "epoch": 0.0842948211369264,
      "grad_norm": 0.4424546957015991,
      "learning_rate": 9.161045531197303e-06,
      "loss": 1.521,
      "step": 200
    },
    {
      "epoch": 0.08850956219377272,
      "grad_norm": 0.4490055739879608,
      "learning_rate": 9.118887015177066e-06,
      "loss": 1.5303,
      "step": 210
    },
    {
      "epoch": 0.09272430325061903,
      "grad_norm": 0.44317153096199036,
      "learning_rate": 9.07672849915683e-06,
      "loss": 1.5183,
      "step": 220
    },
    {
      "epoch": 0.09693904430746536,
      "grad_norm": 0.4359557032585144,
      "learning_rate": 9.034569983136593e-06,
      "loss": 1.5168,
      "step": 230
    },
    {
      "epoch": 0.10115378536431167,
      "grad_norm": 0.4430941343307495,
      "learning_rate": 8.992411467116358e-06,
      "loss": 1.5284,
      "step": 240
    },
    {
      "epoch": 0.105368526421158,
      "grad_norm": 0.4388042688369751,
      "learning_rate": 8.950252951096122e-06,
      "loss": 1.5302,
      "step": 250
    },
    {
      "epoch": 0.10958326747800431,
      "grad_norm": 0.4342043995857239,
      "learning_rate": 8.908094435075885e-06,
      "loss": 1.5153,
      "step": 260
    },
    {
      "epoch": 0.11379800853485064,
      "grad_norm": 0.4418816864490509,
      "learning_rate": 8.86593591905565e-06,
      "loss": 1.5206,
      "step": 270
    },
    {
      "epoch": 0.11801274959169696,
      "grad_norm": 0.44444072246551514,
      "learning_rate": 8.823777403035414e-06,
      "loss": 1.523,
      "step": 280
    },
    {
      "epoch": 0.12222749064854328,
      "grad_norm": 0.43652018904685974,
      "learning_rate": 8.781618887015177e-06,
      "loss": 1.5105,
      "step": 290
    },
    {
      "epoch": 0.1264422317053896,
      "grad_norm": 0.44601765275001526,
      "learning_rate": 8.739460370994943e-06,
      "loss": 1.5131,
      "step": 300
    },
    {
      "epoch": 0.13065697276223592,
      "grad_norm": 0.43915385007858276,
      "learning_rate": 8.697301854974706e-06,
      "loss": 1.5215,
      "step": 310
    },
    {
      "epoch": 0.13487171381908225,
      "grad_norm": 0.43536409735679626,
      "learning_rate": 8.65514333895447e-06,
      "loss": 1.5101,
      "step": 320
    },
    {
      "epoch": 0.13908645487592855,
      "grad_norm": 0.4283086955547333,
      "learning_rate": 8.612984822934233e-06,
      "loss": 1.5131,
      "step": 330
    },
    {
      "epoch": 0.14330119593277488,
      "grad_norm": 0.44212040305137634,
      "learning_rate": 8.570826306913998e-06,
      "loss": 1.5004,
      "step": 340
    },
    {
      "epoch": 0.1475159369896212,
      "grad_norm": 0.430169016122818,
      "learning_rate": 8.528667790893762e-06,
      "loss": 1.5167,
      "step": 350
    },
    {
      "epoch": 0.15173067804646753,
      "grad_norm": 0.45123687386512756,
      "learning_rate": 8.486509274873525e-06,
      "loss": 1.5188,
      "step": 360
    },
    {
      "epoch": 0.15594541910331383,
      "grad_norm": 0.43340209126472473,
      "learning_rate": 8.444350758853289e-06,
      "loss": 1.5096,
      "step": 370
    },
    {
      "epoch": 0.16016016016016016,
      "grad_norm": 0.4298398196697235,
      "learning_rate": 8.402192242833052e-06,
      "loss": 1.4952,
      "step": 380
    },
    {
      "epoch": 0.16437490121700649,
      "grad_norm": 0.44129276275634766,
      "learning_rate": 8.360033726812817e-06,
      "loss": 1.4961,
      "step": 390
    },
    {
      "epoch": 0.1685896422738528,
      "grad_norm": 0.4358513057231903,
      "learning_rate": 8.31787521079258e-06,
      "loss": 1.5033,
      "step": 400
    },
    {
      "epoch": 0.1728043833306991,
      "grad_norm": 0.42798468470573425,
      "learning_rate": 8.275716694772344e-06,
      "loss": 1.5117,
      "step": 410
    },
    {
      "epoch": 0.17701912438754544,
      "grad_norm": 0.4327538311481476,
      "learning_rate": 8.23355817875211e-06,
      "loss": 1.5051,
      "step": 420
    },
    {
      "epoch": 0.18123386544439177,
      "grad_norm": 0.43614068627357483,
      "learning_rate": 8.191399662731873e-06,
      "loss": 1.5095,
      "step": 430
    },
    {
      "epoch": 0.18544860650123807,
      "grad_norm": 0.4329775273799896,
      "learning_rate": 8.149241146711636e-06,
      "loss": 1.5095,
      "step": 440
    },
    {
      "epoch": 0.1896633475580844,
      "grad_norm": 0.42443591356277466,
      "learning_rate": 8.107082630691401e-06,
      "loss": 1.4937,
      "step": 450
    },
    {
      "epoch": 0.19387808861493072,
      "grad_norm": 0.4366770088672638,
      "learning_rate": 8.064924114671165e-06,
      "loss": 1.4912,
      "step": 460
    },
    {
      "epoch": 0.19809282967177705,
      "grad_norm": 0.44169333577156067,
      "learning_rate": 8.022765598650928e-06,
      "loss": 1.5035,
      "step": 470
    },
    {
      "epoch": 0.20230757072862335,
      "grad_norm": 0.42259272933006287,
      "learning_rate": 7.980607082630692e-06,
      "loss": 1.499,
      "step": 480
    },
    {
      "epoch": 0.20652231178546968,
      "grad_norm": 0.4454236924648285,
      "learning_rate": 7.938448566610455e-06,
      "loss": 1.5045,
      "step": 490
    },
    {
      "epoch": 0.210737052842316,
      "grad_norm": 0.43375545740127563,
      "learning_rate": 7.89629005059022e-06,
      "loss": 1.4987,
      "step": 500
    },
    {
      "epoch": 0.21495179389916233,
      "grad_norm": 0.43711042404174805,
      "learning_rate": 7.854131534569984e-06,
      "loss": 1.5068,
      "step": 510
    },
    {
      "epoch": 0.21916653495600863,
      "grad_norm": 0.43148210644721985,
      "learning_rate": 7.811973018549747e-06,
      "loss": 1.4975,
      "step": 520
    },
    {
      "epoch": 0.22338127601285496,
      "grad_norm": 0.4463367462158203,
      "learning_rate": 7.76981450252951e-06,
      "loss": 1.4967,
      "step": 530
    },
    {
      "epoch": 0.22759601706970128,
      "grad_norm": 0.4521624743938446,
      "learning_rate": 7.727655986509276e-06,
      "loss": 1.4961,
      "step": 540
    },
    {
      "epoch": 0.2318107581265476,
      "grad_norm": 0.4416029751300812,
      "learning_rate": 7.68549747048904e-06,
      "loss": 1.4891,
      "step": 550
    },
    {
      "epoch": 0.2360254991833939,
      "grad_norm": 0.43792128562927246,
      "learning_rate": 7.643338954468803e-06,
      "loss": 1.5066,
      "step": 560
    },
    {
      "epoch": 0.24024024024024024,
      "grad_norm": 0.43265455961227417,
      "learning_rate": 7.601180438448568e-06,
      "loss": 1.4979,
      "step": 570
    },
    {
      "epoch": 0.24445498129708657,
      "grad_norm": 0.43965986371040344,
      "learning_rate": 7.5590219224283315e-06,
      "loss": 1.4983,
      "step": 580
    },
    {
      "epoch": 0.2486697223539329,
      "grad_norm": 0.4298798143863678,
      "learning_rate": 7.516863406408095e-06,
      "loss": 1.4984,
      "step": 590
    },
    {
      "epoch": 0.2528844634107792,
      "grad_norm": 0.43869057297706604,
      "learning_rate": 7.474704890387859e-06,
      "loss": 1.495,
      "step": 600
    },
    {
      "epoch": 0.2570992044676255,
      "grad_norm": 0.43337273597717285,
      "learning_rate": 7.432546374367623e-06,
      "loss": 1.4954,
      "step": 610
    },
    {
      "epoch": 0.26131394552447185,
      "grad_norm": 0.44039496779441833,
      "learning_rate": 7.390387858347386e-06,
      "loss": 1.4925,
      "step": 620
    },
    {
      "epoch": 0.2655286865813182,
      "grad_norm": 0.4387598931789398,
      "learning_rate": 7.348229342327151e-06,
      "loss": 1.4977,
      "step": 630
    },
    {
      "epoch": 0.2697434276381645,
      "grad_norm": 0.43999171257019043,
      "learning_rate": 7.306070826306915e-06,
      "loss": 1.5006,
      "step": 640
    },
    {
      "epoch": 0.2739581686950108,
      "grad_norm": 0.4458537995815277,
      "learning_rate": 7.263912310286678e-06,
      "loss": 1.4886,
      "step": 650
    },
    {
      "epoch": 0.2781729097518571,
      "grad_norm": 0.43359020352363586,
      "learning_rate": 7.221753794266443e-06,
      "loss": 1.5011,
      "step": 660
    },
    {
      "epoch": 0.2823876508087034,
      "grad_norm": 0.43802720308303833,
      "learning_rate": 7.179595278246206e-06,
      "loss": 1.4986,
      "step": 670
    },
    {
      "epoch": 0.28660239186554975,
      "grad_norm": 0.4323129653930664,
      "learning_rate": 7.1374367622259695e-06,
      "loss": 1.4924,
      "step": 680
    },
    {
      "epoch": 0.2908171329223961,
      "grad_norm": 0.43656978011131287,
      "learning_rate": 7.095278246205735e-06,
      "loss": 1.4877,
      "step": 690
    },
    {
      "epoch": 0.2950318739792424,
      "grad_norm": 0.4485556483268738,
      "learning_rate": 7.053119730185498e-06,
      "loss": 1.4982,
      "step": 700
    },
    {
      "epoch": 0.29924661503608874,
      "grad_norm": 0.43509432673454285,
      "learning_rate": 7.010961214165262e-06,
      "loss": 1.495,
      "step": 710
    },
    {
      "epoch": 0.30346135609293506,
      "grad_norm": 0.433504581451416,
      "learning_rate": 6.968802698145026e-06,
      "loss": 1.4912,
      "step": 720
    },
    {
      "epoch": 0.30767609714978134,
      "grad_norm": 0.44165781140327454,
      "learning_rate": 6.92664418212479e-06,
      "loss": 1.4943,
      "step": 730
    },
    {
      "epoch": 0.31189083820662766,
      "grad_norm": 0.4405788779258728,
      "learning_rate": 6.884485666104554e-06,
      "loss": 1.4944,
      "step": 740
    },
    {
      "epoch": 0.316105579263474,
      "grad_norm": 0.4373827278614044,
      "learning_rate": 6.842327150084318e-06,
      "loss": 1.494,
      "step": 750
    },
    {
      "epoch": 0.3203203203203203,
      "grad_norm": 0.43305009603500366,
      "learning_rate": 6.8001686340640815e-06,
      "loss": 1.4933,
      "step": 760
    },
    {
      "epoch": 0.32453506137716664,
      "grad_norm": 0.4412318170070648,
      "learning_rate": 6.758010118043845e-06,
      "loss": 1.4953,
      "step": 770
    },
    {
      "epoch": 0.32874980243401297,
      "grad_norm": 0.4345364272594452,
      "learning_rate": 6.71585160202361e-06,
      "loss": 1.5046,
      "step": 780
    },
    {
      "epoch": 0.3329645434908593,
      "grad_norm": 0.4338042438030243,
      "learning_rate": 6.673693086003374e-06,
      "loss": 1.4985,
      "step": 790
    },
    {
      "epoch": 0.3371792845477056,
      "grad_norm": 0.43424174189567566,
      "learning_rate": 6.631534569983137e-06,
      "loss": 1.4879,
      "step": 800
    },
    {
      "epoch": 0.3413940256045519,
      "grad_norm": 0.42972642183303833,
      "learning_rate": 6.589376053962901e-06,
      "loss": 1.4854,
      "step": 810
    },
    {
      "epoch": 0.3456087666613982,
      "grad_norm": 0.44142043590545654,
      "learning_rate": 6.547217537942665e-06,
      "loss": 1.497,
      "step": 820
    },
    {
      "epoch": 0.34982350771824455,
      "grad_norm": 0.44225066900253296,
      "learning_rate": 6.505059021922428e-06,
      "loss": 1.4892,
      "step": 830
    },
    {
      "epoch": 0.3540382487750909,
      "grad_norm": 0.4344467222690582,
      "learning_rate": 6.4629005059021934e-06,
      "loss": 1.4907,
      "step": 840
    },
    {
      "epoch": 0.3582529898319372,
      "grad_norm": 0.4334715008735657,
      "learning_rate": 6.420741989881957e-06,
      "loss": 1.4811,
      "step": 850
    },
    {
      "epoch": 0.36246773088878353,
      "grad_norm": 0.4405005872249603,
      "learning_rate": 6.37858347386172e-06,
      "loss": 1.4806,
      "step": 860
    },
    {
      "epoch": 0.36668247194562986,
      "grad_norm": 0.4372965395450592,
      "learning_rate": 6.336424957841485e-06,
      "loss": 1.4849,
      "step": 870
    },
    {
      "epoch": 0.37089721300247613,
      "grad_norm": 0.44203120470046997,
      "learning_rate": 6.294266441821248e-06,
      "loss": 1.4787,
      "step": 880
    },
    {
      "epoch": 0.37511195405932246,
      "grad_norm": 0.4319346249103546,
      "learning_rate": 6.252107925801012e-06,
      "loss": 1.4894,
      "step": 890
    },
    {
      "epoch": 0.3793266951161688,
      "grad_norm": 0.44119057059288025,
      "learning_rate": 6.209949409780777e-06,
      "loss": 1.4832,
      "step": 900
    },
    {
      "epoch": 0.3835414361730151,
      "grad_norm": 0.4536922872066498,
      "learning_rate": 6.16779089376054e-06,
      "loss": 1.4794,
      "step": 910
    },
    {
      "epoch": 0.38775617722986144,
      "grad_norm": 0.432039350271225,
      "learning_rate": 6.125632377740304e-06,
      "loss": 1.4775,
      "step": 920
    },
    {
      "epoch": 0.39197091828670777,
      "grad_norm": 0.42732372879981995,
      "learning_rate": 6.083473861720068e-06,
      "loss": 1.4933,
      "step": 930
    },
    {
      "epoch": 0.3961856593435541,
      "grad_norm": 0.4410853981971741,
      "learning_rate": 6.041315345699832e-06,
      "loss": 1.4878,
      "step": 940
    },
    {
      "epoch": 0.4004004004004004,
      "grad_norm": 0.4360240399837494,
      "learning_rate": 5.999156829679596e-06,
      "loss": 1.4849,
      "step": 950
    },
    {
      "epoch": 0.4046151414572467,
      "grad_norm": 0.4368644952774048,
      "learning_rate": 5.95699831365936e-06,
      "loss": 1.4843,
      "step": 960
    },
    {
      "epoch": 0.408829882514093,
      "grad_norm": 0.42379406094551086,
      "learning_rate": 5.9148397976391236e-06,
      "loss": 1.4895,
      "step": 970
    },
    {
      "epoch": 0.41304462357093935,
      "grad_norm": 0.4288386106491089,
      "learning_rate": 5.872681281618887e-06,
      "loss": 1.4865,
      "step": 980
    },
    {
      "epoch": 0.4172593646277857,
      "grad_norm": 0.44995221495628357,
      "learning_rate": 5.830522765598652e-06,
      "loss": 1.4796,
      "step": 990
    },
    {
      "epoch": 0.421474105684632,
      "grad_norm": 0.4406016170978546,
      "learning_rate": 5.788364249578416e-06,
      "loss": 1.4865,
      "step": 1000
    },
    {
      "epoch": 0.42568884674147833,
      "grad_norm": 0.4450043737888336,
      "learning_rate": 5.746205733558179e-06,
      "loss": 1.4812,
      "step": 1010
    },
    {
      "epoch": 0.42990358779832466,
      "grad_norm": 0.4365222454071045,
      "learning_rate": 5.7040472175379434e-06,
      "loss": 1.4926,
      "step": 1020
    },
    {
      "epoch": 0.434118328855171,
      "grad_norm": 0.4334902763366699,
      "learning_rate": 5.661888701517707e-06,
      "loss": 1.4793,
      "step": 1030
    },
    {
      "epoch": 0.43833306991201726,
      "grad_norm": 0.427077978849411,
      "learning_rate": 5.61973018549747e-06,
      "loss": 1.4786,
      "step": 1040
    },
    {
      "epoch": 0.4425478109688636,
      "grad_norm": 0.4326914846897125,
      "learning_rate": 5.5775716694772355e-06,
      "loss": 1.4774,
      "step": 1050
    },
    {
      "epoch": 0.4467625520257099,
      "grad_norm": 0.44327661395072937,
      "learning_rate": 5.535413153456999e-06,
      "loss": 1.4873,
      "step": 1060
    },
    {
      "epoch": 0.45097729308255624,
      "grad_norm": 0.42177319526672363,
      "learning_rate": 5.4932546374367625e-06,
      "loss": 1.4734,
      "step": 1070
    },
    {
      "epoch": 0.45519203413940257,
      "grad_norm": 0.43998879194259644,
      "learning_rate": 5.451096121416527e-06,
      "loss": 1.4726,
      "step": 1080
    },
    {
      "epoch": 0.4594067751962489,
      "grad_norm": 0.4306797683238983,
      "learning_rate": 5.40893760539629e-06,
      "loss": 1.4768,
      "step": 1090
    },
    {
      "epoch": 0.4636215162530952,
      "grad_norm": 0.44576776027679443,
      "learning_rate": 5.366779089376054e-06,
      "loss": 1.4959,
      "step": 1100
    },
    {
      "epoch": 0.4678362573099415,
      "grad_norm": 0.44523972272872925,
      "learning_rate": 5.324620573355819e-06,
      "loss": 1.4804,
      "step": 1110
    },
    {
      "epoch": 0.4720509983667878,
      "grad_norm": 0.42974424362182617,
      "learning_rate": 5.282462057335582e-06,
      "loss": 1.4832,
      "step": 1120
    },
    {
      "epoch": 0.47626573942363415,
      "grad_norm": 0.4266290068626404,
      "learning_rate": 5.240303541315346e-06,
      "loss": 1.4752,
      "step": 1130
    },
    {
      "epoch": 0.4804804804804805,
      "grad_norm": 0.4412665367126465,
      "learning_rate": 5.19814502529511e-06,
      "loss": 1.4731,
      "step": 1140
    },
    {
      "epoch": 0.4846952215373268,
      "grad_norm": 0.43304795026779175,
      "learning_rate": 5.155986509274874e-06,
      "loss": 1.4846,
      "step": 1150
    },
    {
      "epoch": 0.48890996259417313,
      "grad_norm": 0.4427069425582886,
      "learning_rate": 5.113827993254638e-06,
      "loss": 1.4852,
      "step": 1160
    },
    {
      "epoch": 0.49312470365101946,
      "grad_norm": 0.4472263753414154,
      "learning_rate": 5.071669477234402e-06,
      "loss": 1.4831,
      "step": 1170
    },
    {
      "epoch": 0.4973394447078658,
      "grad_norm": 0.434536874294281,
      "learning_rate": 5.029510961214166e-06,
      "loss": 1.4831,
      "step": 1180
    },
    {
      "epoch": 0.5015541857647121,
      "grad_norm": 0.4491637349128723,
      "learning_rate": 4.98735244519393e-06,
      "loss": 1.4795,
      "step": 1190
    },
    {
      "epoch": 0.5057689268215584,
      "grad_norm": 0.43411731719970703,
      "learning_rate": 4.945193929173693e-06,
      "loss": 1.4697,
      "step": 1200
    },
    {
      "epoch": 0.5099836678784048,
      "grad_norm": 0.4425075054168701,
      "learning_rate": 4.903035413153458e-06,
      "loss": 1.4724,
      "step": 1210
    },
    {
      "epoch": 0.514198408935251,
      "grad_norm": 0.4406909644603729,
      "learning_rate": 4.860876897133221e-06,
      "loss": 1.4704,
      "step": 1220
    },
    {
      "epoch": 0.5184131499920973,
      "grad_norm": 0.428021639585495,
      "learning_rate": 4.818718381112985e-06,
      "loss": 1.4773,
      "step": 1230
    },
    {
      "epoch": 0.5226278910489437,
      "grad_norm": 0.4344344735145569,
      "learning_rate": 4.776559865092749e-06,
      "loss": 1.474,
      "step": 1240
    },
    {
      "epoch": 0.52684263210579,
      "grad_norm": 0.42686283588409424,
      "learning_rate": 4.734401349072513e-06,
      "loss": 1.4706,
      "step": 1250
    },
    {
      "epoch": 0.5310573731626363,
      "grad_norm": 0.43468841910362244,
      "learning_rate": 4.692242833052277e-06,
      "loss": 1.4758,
      "step": 1260
    },
    {
      "epoch": 0.5352721142194826,
      "grad_norm": 0.4357227087020874,
      "learning_rate": 4.650084317032041e-06,
      "loss": 1.4844,
      "step": 1270
    },
    {
      "epoch": 0.539486855276329,
      "grad_norm": 0.44490233063697815,
      "learning_rate": 4.607925801011805e-06,
      "loss": 1.4766,
      "step": 1280
    },
    {
      "epoch": 0.5437015963331753,
      "grad_norm": 0.4175339639186859,
      "learning_rate": 4.565767284991569e-06,
      "loss": 1.4724,
      "step": 1290
    },
    {
      "epoch": 0.5479163373900215,
      "grad_norm": 0.4382335841655731,
      "learning_rate": 4.523608768971332e-06,
      "loss": 1.471,
      "step": 1300
    },
    {
      "epoch": 0.5521310784468679,
      "grad_norm": 0.45075124502182007,
      "learning_rate": 4.481450252951097e-06,
      "loss": 1.481,
      "step": 1310
    },
    {
      "epoch": 0.5563458195037142,
      "grad_norm": 0.4419011175632477,
      "learning_rate": 4.43929173693086e-06,
      "loss": 1.482,
      "step": 1320
    },
    {
      "epoch": 0.5605605605605606,
      "grad_norm": 0.43055450916290283,
      "learning_rate": 4.397133220910624e-06,
      "loss": 1.4715,
      "step": 1330
    },
    {
      "epoch": 0.5647753016174069,
      "grad_norm": 0.44045957922935486,
      "learning_rate": 4.354974704890389e-06,
      "loss": 1.4718,
      "step": 1340
    },
    {
      "epoch": 0.5689900426742532,
      "grad_norm": 0.42766067385673523,
      "learning_rate": 4.312816188870152e-06,
      "loss": 1.4772,
      "step": 1350
    },
    {
      "epoch": 0.5732047837310995,
      "grad_norm": 0.43843087553977966,
      "learning_rate": 4.2706576728499165e-06,
      "loss": 1.4777,
      "step": 1360
    },
    {
      "epoch": 0.5774195247879459,
      "grad_norm": 0.4364432692527771,
      "learning_rate": 4.22849915682968e-06,
      "loss": 1.4733,
      "step": 1370
    },
    {
      "epoch": 0.5816342658447922,
      "grad_norm": 0.4275084435939789,
      "learning_rate": 4.186340640809443e-06,
      "loss": 1.4776,
      "step": 1380
    },
    {
      "epoch": 0.5858490069016384,
      "grad_norm": 0.4293730854988098,
      "learning_rate": 4.144182124789208e-06,
      "loss": 1.4855,
      "step": 1390
    },
    {
      "epoch": 0.5900637479584848,
      "grad_norm": 0.43135905265808105,
      "learning_rate": 4.102023608768972e-06,
      "loss": 1.4704,
      "step": 1400
    },
    {
      "epoch": 0.5942784890153311,
      "grad_norm": 0.4423084557056427,
      "learning_rate": 4.0598650927487355e-06,
      "loss": 1.4737,
      "step": 1410
    },
    {
      "epoch": 0.5984932300721775,
      "grad_norm": 0.42827534675598145,
      "learning_rate": 4.0177065767285e-06,
      "loss": 1.4752,
      "step": 1420
    },
    {
      "epoch": 0.6027079711290237,
      "grad_norm": 0.4393116235733032,
      "learning_rate": 3.975548060708263e-06,
      "loss": 1.4857,
      "step": 1430
    },
    {
      "epoch": 0.6069227121858701,
      "grad_norm": 0.433034747838974,
      "learning_rate": 3.933389544688027e-06,
      "loss": 1.4767,
      "step": 1440
    },
    {
      "epoch": 0.6111374532427164,
      "grad_norm": 0.43273037672042847,
      "learning_rate": 3.891231028667791e-06,
      "loss": 1.4724,
      "step": 1450
    },
    {
      "epoch": 0.6153521942995627,
      "grad_norm": 0.43448135256767273,
      "learning_rate": 3.849072512647555e-06,
      "loss": 1.4759,
      "step": 1460
    },
    {
      "epoch": 0.619566935356409,
      "grad_norm": 0.4326424300670624,
      "learning_rate": 3.806913996627319e-06,
      "loss": 1.4716,
      "step": 1470
    },
    {
      "epoch": 0.6237816764132553,
      "grad_norm": 0.4387497007846832,
      "learning_rate": 3.764755480607083e-06,
      "loss": 1.476,
      "step": 1480
    },
    {
      "epoch": 0.6279964174701017,
      "grad_norm": 0.4363568127155304,
      "learning_rate": 3.722596964586847e-06,
      "loss": 1.4826,
      "step": 1490
    },
    {
      "epoch": 0.632211158526948,
      "grad_norm": 0.43586450815200806,
      "learning_rate": 3.6804384485666105e-06,
      "loss": 1.4879,
      "step": 1500
    },
    {
      "epoch": 0.6364258995837944,
      "grad_norm": 0.438003271818161,
      "learning_rate": 3.638279932546375e-06,
      "loss": 1.4718,
      "step": 1510
    },
    {
      "epoch": 0.6406406406406406,
      "grad_norm": 0.4350798726081848,
      "learning_rate": 3.5961214165261387e-06,
      "loss": 1.4761,
      "step": 1520
    },
    {
      "epoch": 0.6448553816974869,
      "grad_norm": 0.448225200176239,
      "learning_rate": 3.553962900505902e-06,
      "loss": 1.4722,
      "step": 1530
    },
    {
      "epoch": 0.6490701227543333,
      "grad_norm": 0.43016403913497925,
      "learning_rate": 3.5118043844856665e-06,
      "loss": 1.4693,
      "step": 1540
    },
    {
      "epoch": 0.6532848638111796,
      "grad_norm": 0.44267237186431885,
      "learning_rate": 3.4696458684654304e-06,
      "loss": 1.4644,
      "step": 1550
    },
    {
      "epoch": 0.6574996048680259,
      "grad_norm": 0.4415999948978424,
      "learning_rate": 3.4274873524451942e-06,
      "loss": 1.4776,
      "step": 1560
    },
    {
      "epoch": 0.6617143459248722,
      "grad_norm": 0.44312119483947754,
      "learning_rate": 3.385328836424958e-06,
      "loss": 1.4778,
      "step": 1570
    },
    {
      "epoch": 0.6659290869817186,
      "grad_norm": 0.4333250820636749,
      "learning_rate": 3.343170320404722e-06,
      "loss": 1.4752,
      "step": 1580
    },
    {
      "epoch": 0.6701438280385649,
      "grad_norm": 0.4362395405769348,
      "learning_rate": 3.301011804384486e-06,
      "loss": 1.4677,
      "step": 1590
    },
    {
      "epoch": 0.6743585690954113,
      "grad_norm": 0.4381239414215088,
      "learning_rate": 3.25885328836425e-06,
      "loss": 1.4773,
      "step": 1600
    },
    {
      "epoch": 0.6785733101522575,
      "grad_norm": 0.4394706189632416,
      "learning_rate": 3.216694772344014e-06,
      "loss": 1.4609,
      "step": 1610
    },
    {
      "epoch": 0.6827880512091038,
      "grad_norm": 0.4302555024623871,
      "learning_rate": 3.1745362563237776e-06,
      "loss": 1.4745,
      "step": 1620
    },
    {
      "epoch": 0.6870027922659502,
      "grad_norm": 0.428478866815567,
      "learning_rate": 3.1323777403035415e-06,
      "loss": 1.4756,
      "step": 1630
    },
    {
      "epoch": 0.6912175333227965,
      "grad_norm": 0.43739065527915955,
      "learning_rate": 3.0902192242833058e-06,
      "loss": 1.4702,
      "step": 1640
    },
    {
      "epoch": 0.6954322743796428,
      "grad_norm": 0.447395384311676,
      "learning_rate": 3.0480607082630692e-06,
      "loss": 1.4748,
      "step": 1650
    },
    {
      "epoch": 0.6996470154364891,
      "grad_norm": 0.4294537901878357,
      "learning_rate": 3.005902192242833e-06,
      "loss": 1.4746,
      "step": 1660
    },
    {
      "epoch": 0.7038617564933355,
      "grad_norm": 0.43242347240448,
      "learning_rate": 2.9637436762225974e-06,
      "loss": 1.4711,
      "step": 1670
    },
    {
      "epoch": 0.7080764975501818,
      "grad_norm": 0.4200437068939209,
      "learning_rate": 2.921585160202361e-06,
      "loss": 1.4541,
      "step": 1680
    },
    {
      "epoch": 0.712291238607028,
      "grad_norm": 0.43832358717918396,
      "learning_rate": 2.879426644182125e-06,
      "loss": 1.4742,
      "step": 1690
    },
    {
      "epoch": 0.7165059796638744,
      "grad_norm": 0.42868223786354065,
      "learning_rate": 2.837268128161889e-06,
      "loss": 1.4735,
      "step": 1700
    },
    {
      "epoch": 0.7207207207207207,
      "grad_norm": 0.44463592767715454,
      "learning_rate": 2.7951096121416526e-06,
      "loss": 1.4718,
      "step": 1710
    },
    {
      "epoch": 0.7249354617775671,
      "grad_norm": 0.43711063265800476,
      "learning_rate": 2.752951096121417e-06,
      "loss": 1.4698,
      "step": 1720
    },
    {
      "epoch": 0.7291502028344133,
      "grad_norm": 0.4307210147380829,
      "learning_rate": 2.7107925801011808e-06,
      "loss": 1.4669,
      "step": 1730
    },
    {
      "epoch": 0.7333649438912597,
      "grad_norm": 0.43399813771247864,
      "learning_rate": 2.6686340640809442e-06,
      "loss": 1.4601,
      "step": 1740
    },
    {
      "epoch": 0.737579684948106,
      "grad_norm": 0.4326317608356476,
      "learning_rate": 2.6264755480607085e-06,
      "loss": 1.476,
      "step": 1750
    },
    {
      "epoch": 0.7417944260049523,
      "grad_norm": 0.4362240731716156,
      "learning_rate": 2.5843170320404724e-06,
      "loss": 1.4708,
      "step": 1760
    },
    {
      "epoch": 0.7460091670617987,
      "grad_norm": 0.45797470211982727,
      "learning_rate": 2.5421585160202363e-06,
      "loss": 1.4748,
      "step": 1770
    },
    {
      "epoch": 0.7502239081186449,
      "grad_norm": 0.43394866585731506,
      "learning_rate": 2.5e-06,
      "loss": 1.4654,
      "step": 1780
    },
    {
      "epoch": 0.7544386491754913,
      "grad_norm": 0.4363211989402771,
      "learning_rate": 2.457841483979764e-06,
      "loss": 1.4653,
      "step": 1790
    },
    {
      "epoch": 0.7586533902323376,
      "grad_norm": 0.43257978558540344,
      "learning_rate": 2.415682967959528e-06,
      "loss": 1.4715,
      "step": 1800
    },
    {
      "epoch": 0.762868131289184,
      "grad_norm": 0.4360516667366028,
      "learning_rate": 2.373524451939292e-06,
      "loss": 1.4652,
      "step": 1810
    },
    {
      "epoch": 0.7670828723460302,
      "grad_norm": 0.43070685863494873,
      "learning_rate": 2.3313659359190558e-06,
      "loss": 1.4721,
      "step": 1820
    },
    {
      "epoch": 0.7712976134028766,
      "grad_norm": 0.4391218423843384,
      "learning_rate": 2.2892074198988196e-06,
      "loss": 1.4761,
      "step": 1830
    },
    {
      "epoch": 0.7755123544597229,
      "grad_norm": 0.4331369698047638,
      "learning_rate": 2.2470489038785835e-06,
      "loss": 1.4655,
      "step": 1840
    },
    {
      "epoch": 0.7797270955165692,
      "grad_norm": 0.4344858229160309,
      "learning_rate": 2.2048903878583474e-06,
      "loss": 1.4746,
      "step": 1850
    },
    {
      "epoch": 0.7839418365734155,
      "grad_norm": 0.44074541330337524,
      "learning_rate": 2.1627318718381117e-06,
      "loss": 1.473,
      "step": 1860
    },
    {
      "epoch": 0.7881565776302618,
      "grad_norm": 0.4311600923538208,
      "learning_rate": 2.120573355817875e-06,
      "loss": 1.4702,
      "step": 1870
    },
    {
      "epoch": 0.7923713186871082,
      "grad_norm": 0.43947839736938477,
      "learning_rate": 2.078414839797639e-06,
      "loss": 1.4751,
      "step": 1880
    },
    {
      "epoch": 0.7965860597439545,
      "grad_norm": 0.4327083230018616,
      "learning_rate": 2.0362563237774034e-06,
      "loss": 1.4697,
      "step": 1890
    },
    {
      "epoch": 0.8008008008008008,
      "grad_norm": 0.4362989068031311,
      "learning_rate": 1.9940978077571673e-06,
      "loss": 1.4612,
      "step": 1900
    },
    {
      "epoch": 0.8050155418576471,
      "grad_norm": 0.43270280957221985,
      "learning_rate": 1.9519392917369308e-06,
      "loss": 1.471,
      "step": 1910
    },
    {
      "epoch": 0.8092302829144934,
      "grad_norm": 0.4348354637622833,
      "learning_rate": 1.909780775716695e-06,
      "loss": 1.4707,
      "step": 1920
    },
    {
      "epoch": 0.8134450239713398,
      "grad_norm": 0.4347499907016754,
      "learning_rate": 1.8676222596964587e-06,
      "loss": 1.4671,
      "step": 1930
    },
    {
      "epoch": 0.817659765028186,
      "grad_norm": 0.42411014437675476,
      "learning_rate": 1.8254637436762226e-06,
      "loss": 1.4598,
      "step": 1940
    },
    {
      "epoch": 0.8218745060850324,
      "grad_norm": 0.4338984191417694,
      "learning_rate": 1.7833052276559867e-06,
      "loss": 1.4711,
      "step": 1950
    },
    {
      "epoch": 0.8260892471418787,
      "grad_norm": 0.44122761487960815,
      "learning_rate": 1.7411467116357506e-06,
      "loss": 1.4728,
      "step": 1960
    },
    {
      "epoch": 0.8303039881987251,
      "grad_norm": 0.43789273500442505,
      "learning_rate": 1.6989881956155143e-06,
      "loss": 1.4809,
      "step": 1970
    },
    {
      "epoch": 0.8345187292555714,
      "grad_norm": 0.4326297640800476,
      "learning_rate": 1.6568296795952784e-06,
      "loss": 1.4709,
      "step": 1980
    },
    {
      "epoch": 0.8387334703124176,
      "grad_norm": 0.4363274872303009,
      "learning_rate": 1.6146711635750423e-06,
      "loss": 1.4621,
      "step": 1990
    },
    {
      "epoch": 0.842948211369264,
      "grad_norm": 0.4396217465400696,
      "learning_rate": 1.5725126475548062e-06,
      "loss": 1.4706,
      "step": 2000
    },
    {
      "epoch": 0.8471629524261103,
      "grad_norm": 0.4526538848876953,
      "learning_rate": 1.5303541315345703e-06,
      "loss": 1.4727,
      "step": 2010
    },
    {
      "epoch": 0.8513776934829567,
      "grad_norm": 0.43084362149238586,
      "learning_rate": 1.488195615514334e-06,
      "loss": 1.4633,
      "step": 2020
    },
    {
      "epoch": 0.8555924345398029,
      "grad_norm": 0.43046924471855164,
      "learning_rate": 1.4460370994940978e-06,
      "loss": 1.4689,
      "step": 2030
    },
    {
      "epoch": 0.8598071755966493,
      "grad_norm": 0.4357738792896271,
      "learning_rate": 1.403878583473862e-06,
      "loss": 1.4735,
      "step": 2040
    },
    {
      "epoch": 0.8640219166534956,
      "grad_norm": 0.4250246584415436,
      "learning_rate": 1.3617200674536258e-06,
      "loss": 1.4646,
      "step": 2050
    },
    {
      "epoch": 0.868236657710342,
      "grad_norm": 0.43590930104255676,
      "learning_rate": 1.3195615514333895e-06,
      "loss": 1.4676,
      "step": 2060
    },
    {
      "epoch": 0.8724513987671882,
      "grad_norm": 0.4335828423500061,
      "learning_rate": 1.2774030354131536e-06,
      "loss": 1.4661,
      "step": 2070
    },
    {
      "epoch": 0.8766661398240345,
      "grad_norm": 0.44146043062210083,
      "learning_rate": 1.2352445193929175e-06,
      "loss": 1.477,
      "step": 2080
    },
    {
      "epoch": 0.8808808808808809,
      "grad_norm": 0.4507286846637726,
      "learning_rate": 1.1930860033726814e-06,
      "loss": 1.4616,
      "step": 2090
    },
    {
      "epoch": 0.8850956219377272,
      "grad_norm": 0.4351520836353302,
      "learning_rate": 1.1509274873524453e-06,
      "loss": 1.4672,
      "step": 2100
    },
    {
      "epoch": 0.8893103629945736,
      "grad_norm": 0.42816388607025146,
      "learning_rate": 1.1087689713322091e-06,
      "loss": 1.4748,
      "step": 2110
    },
    {
      "epoch": 0.8935251040514198,
      "grad_norm": 0.4416244328022003,
      "learning_rate": 1.066610455311973e-06,
      "loss": 1.4722,
      "step": 2120
    },
    {
      "epoch": 0.8977398451082662,
      "grad_norm": 0.4341143071651459,
      "learning_rate": 1.024451939291737e-06,
      "loss": 1.4704,
      "step": 2130
    },
    {
      "epoch": 0.9019545861651125,
      "grad_norm": 0.43827125430107117,
      "learning_rate": 9.822934232715008e-07,
      "loss": 1.4698,
      "step": 2140
    },
    {
      "epoch": 0.9061693272219588,
      "grad_norm": 0.4332256019115448,
      "learning_rate": 9.401349072512648e-07,
      "loss": 1.4685,
      "step": 2150
    },
    {
      "epoch": 0.9103840682788051,
      "grad_norm": 0.4287572205066681,
      "learning_rate": 8.979763912310288e-07,
      "loss": 1.4609,
      "step": 2160
    },
    {
      "epoch": 0.9145988093356514,
      "grad_norm": 0.4297880530357361,
      "learning_rate": 8.558178752107926e-07,
      "loss": 1.4645,
      "step": 2170
    },
    {
      "epoch": 0.9188135503924978,
      "grad_norm": 0.43110761046409607,
      "learning_rate": 8.136593591905566e-07,
      "loss": 1.4716,
      "step": 2180
    },
    {
      "epoch": 0.9230282914493441,
      "grad_norm": 0.4350850284099579,
      "learning_rate": 7.715008431703206e-07,
      "loss": 1.4693,
      "step": 2190
    },
    {
      "epoch": 0.9272430325061904,
      "grad_norm": 0.42529362440109253,
      "learning_rate": 7.293423271500844e-07,
      "loss": 1.4635,
      "step": 2200
    }
  ],
  "logging_steps": 10,
  "max_steps": 2372,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.943193448448e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
